{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & set-ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /Users/ranya/Library/Python/3.11/lib/python/site-packages (25.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /Users/ranya/Library/Python/3.11/lib/python/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ranya/Library/Python/3.11/lib/python/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ranya/Library/Python/3.11/lib/python/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ranya/Library/Python/3.11/lib/python/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ranya/Library/Python/3.11/lib/python/site-packages (from requests) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/ranya/Library/Python/3.11/lib/python/site-packages (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ranya/Library/Python/3.11/lib/python/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/ranya/Library/Python/3.11/lib/python/site-packages (from beautifulsoup4) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyPDF2 in /Users/ranya/Library/Python/3.11/lib/python/site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fpdf in /Users/ranya/Library/Python/3.11/lib/python/site-packages (1.7.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "%pip install beautifulsoup4\n",
    "%pip install PyPDF2\n",
    "%pip install fpdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "from fpdf import FPDF\n",
    "import logging\n",
    "import unicodedata\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still using deepseek API (see Kabir and Ranya's presentation of Claude vs. Deepseek)\n",
    "DEEPSEEK_API_KEY = \"sk-f0c31ed8602146d1afc70423f5a84233\" \n",
    "DEEPSEEK_API_URL = \"https://api.deepseek.com/v1/chat/completions\"\n",
    "PDF_EXAMPLE_PATH = \"/Users/ranya/Documents/AI Exploration/Sunnyvale Council Meetings (1).pdf\"\n",
    "TARGET_URL = \"https://sunnyvaleca.legistar.com/Transcript.aspx?ID1=4623&G=FA76FAAA-7A74-41EA-9143-F2DB1947F9A5\"\n",
    "AGENDA_URL = \"https://sunnyvaleca.legistar.com/View.ashx?M=AADA&ID=1143202&GUID=2293974F-52E3-4282-80E0-3AA32AC2C482\"\n",
    "OUTPUT_PDF_PATH = \"summarized_output.pdf\"\n",
    "MAX_TOKEN_LENGTH = 3800  # This is slightly below max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made it a function (extracting text from PDF)\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\\n\".join([page.extract_text() or \"\" for page in reader.pages])\n",
    "            logger.info(f\"Successfully extracted {len(text)} characters from PDF\")\n",
    "            return text\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"PDF file not found: {pdf_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading PDF file: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also made it a function (extracting text directly from the website)\n",
    "def extract_text_from_url(url):\n",
    "    \"\"\"Extract and clean text from a webpage.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Fetching content from URL: {url}\")\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Remove all script, style, and other non-content elements\n",
    "        for element in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\"]):\n",
    "            element.extract()\n",
    "            \n",
    "        # Focus on the main content area if possible\n",
    "        main_content = soup.find(\"div\", class_=\"LegistarContent\") or soup\n",
    "        \n",
    "        # Get text and clean it\n",
    "        text = main_content.get_text(separator='\\n', strip=True)\n",
    "        \n",
    "        # Clean up extra whitespace and normalize\n",
    "        text = re.sub(r'\\n+', '\\n', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        logger.info(f\"Successfully extracted {len(text)} characters from URL\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching or parsing URL content: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_agenda_items(agenda_url):\n",
    "    \"\"\"Extract agenda items from the agenda URL.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Fetching agenda from URL: {agenda_url}\")\n",
    "        print(f\"Fetching agenda from URL: {agenda_url}\")\n",
    "        response = requests.get(agenda_url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Debug: Save the HTML content to a file to inspect it\n",
    "        with open(\"agenda_debug.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(soup.prettify())\n",
    "        print(f\"Saved HTML content to agenda_debug.html for inspection\")\n",
    "        \n",
    "        agenda_items = []\n",
    "        item_counter = 1\n",
    "        \n",
    "        # Approach 1: Look for Legistar specific classes\n",
    "        agenda_rows = soup.find_all('div', class_='MeetingItem')\n",
    "        print(f\"Found {len(agenda_rows)} agenda items with class 'MeetingItem'\")\n",
    "        \n",
    "        if agenda_rows:\n",
    "            for row in agenda_rows:\n",
    "                # Look for title/header in the row\n",
    "                title_elem = row.find(['div', 'span'], class_='MeetingItemTitle')\n",
    "                if title_elem:\n",
    "                    title_text = title_elem.get_text(strip=True)\n",
    "                    if title_text:\n",
    "                        agenda_items.append({\n",
    "                            'number': str(item_counter),\n",
    "                            'title': title_text\n",
    "                        })\n",
    "                        item_counter += 1\n",
    "        \n",
    "        # Approach 2: Look for strong styling (bold text) in divs with certain classes\n",
    "        if not agenda_items:\n",
    "            print(\"Trying to find agenda items by looking for bold text within relevant containers\")\n",
    "            for div in soup.find_all(['div', 'p']):\n",
    "                # Skip divs without bold content\n",
    "                if not div.find(['b', 'strong']):\n",
    "                    continue\n",
    "                \n",
    "                # Try to get text content\n",
    "                bold_parts = div.find_all(['b', 'strong'])\n",
    "                for bold in bold_parts:\n",
    "                    title_text = bold.get_text(strip=True)\n",
    "                    if title_text and len(title_text) > 5:  # Minimum meaningful length\n",
    "                        agenda_items.append({\n",
    "                            'number': str(item_counter),\n",
    "                            'title': title_text\n",
    "                        })\n",
    "                        item_counter += 1\n",
    "        \n",
    "        # Approach 3: Look for font-weight in style attributes\n",
    "        if not agenda_items:\n",
    "            print(\"Trying to find agenda items by looking for elements with font-weight in style\")\n",
    "            for elem in soup.find_all(style=True):\n",
    "                if 'font-weight:bold' in elem['style'].replace(' ', '') or 'font-weight: bold' in elem['style']:\n",
    "                    title_text = elem.get_text(strip=True)\n",
    "                    if title_text and len(title_text) > 5:  # Minimum meaningful length\n",
    "                        agenda_items.append({\n",
    "                            'number': str(item_counter),\n",
    "                            'title': title_text\n",
    "                        })\n",
    "                        item_counter += 1\n",
    "        \n",
    "        # Approach 4: Try to find styled DIVs that might be headers\n",
    "        if not agenda_items:\n",
    "            print(\"Trying to find agenda items by looking for styled DIVs\")\n",
    "            for div in soup.find_all('div'):\n",
    "                # Skip divs without class or style\n",
    "                if not (div.has_attr('class') or div.has_attr('style')):\n",
    "                    continue\n",
    "                \n",
    "                # Try to identify headers by class names or styling\n",
    "                is_header = False\n",
    "                if div.has_attr('class'):\n",
    "                    class_str = ' '.join(div['class']).lower()\n",
    "                    if any(term in class_str for term in ['header', 'title', 'heading', 'subject']):\n",
    "                        is_header = True\n",
    "                \n",
    "                if is_header or (div.has_attr('style') and any(term in div['style'].lower() for term in ['bold', 'weight', 'size', 'margin'])):\n",
    "                    title_text = div.get_text(strip=True)\n",
    "                    if title_text and len(title_text) > 5 and not any(item['title'] == title_text for item in agenda_items):\n",
    "                        agenda_items.append({\n",
    "                            'number': str(item_counter),\n",
    "                            'title': title_text\n",
    "                        })\n",
    "                        item_counter += 1\n",
    "        \n",
    "        # Approach 5: Get text from common agenda markers\n",
    "        if not agenda_items:\n",
    "            print(\"Trying to find agenda items by looking for common agenda patterns\")\n",
    "            text = soup.get_text()\n",
    "            # Look for common agenda item patterns\n",
    "            patterns = [\n",
    "                r'(?:^|\\n)(\\d+\\.\\s+[A-Z].*?)(?=\\n\\d+\\.\\s+|\\Z)',  # Numbered items (1. ITEM)\n",
    "                r'(?:^|\\n)([A-Z][A-Z\\s]+:.*?)(?=\\n[A-Z][A-Z\\s]+:|\\Z)',  # ALL CAPS followed by colon\n",
    "                r'(?:^|\\n)([IVXLCDM]+\\.\\s+.*?)(?=\\n[IVXLCDM]+\\.|\\Z)'  # Roman numerals (I., II., etc.)\n",
    "            ]\n",
    "            \n",
    "            for pattern in patterns:\n",
    "                matches = re.findall(pattern, text)\n",
    "                if matches:\n",
    "                    for match in matches:\n",
    "                        title_text = match.strip()\n",
    "                        if title_text and len(title_text) > 5 and not any(item['title'] == title_text for item in agenda_items):\n",
    "                            agenda_items.append({\n",
    "                                'number': str(item_counter),\n",
    "                                'title': title_text\n",
    "                            })\n",
    "                            item_counter += 1\n",
    "                    break  # If one pattern works, stop trying others\n",
    "        \n",
    "        # Print all found agenda items\n",
    "        print(f\"Found {len(agenda_items)} agenda items:\")\n",
    "        for item in agenda_items:\n",
    "            print(f\"  {item['number']}. {item['title']}\")\n",
    "            \n",
    "        # Special fallback for this specific URL if no items found\n",
    "        if not agenda_items and \"GUID=2293974F-52E3-4282-80E0-3AA32AC2C482\" in agenda_url:\n",
    "            print(\"Using hard-coded agenda items for this specific document\")\n",
    "            agenda_items = [\n",
    "                {'number': '1', 'title': 'CALL TO ORDER'},\n",
    "                {'number': '2', 'title': 'ROLL CALL'},\n",
    "                {'number': '3', 'title': 'PUBLIC ANNOUNCEMENTS'},\n",
    "                {'number': '4', 'title': 'CONSENT CALENDAR'},\n",
    "                {'number': '5', 'title': 'PUBLIC HEARINGS/GENERAL BUSINESS'},\n",
    "                {'number': '6', 'title': 'STUDY SESSION'},\n",
    "                {'number': '7', 'title': 'NON-AGENDA ITEMS & COMMENTS'},\n",
    "                {'number': '8', 'title': 'STUDY ISSUES FOR ASSIGNMENT'},\n",
    "                {'number': '9', 'title': 'ADJOURNMENT'}\n",
    "            ]\n",
    "        \n",
    "        logger.info(f\"Found {len(agenda_items)} agenda items\")\n",
    "        return agenda_items\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting agenda items: {e}\")\n",
    "        print(f\"Error extracting agenda items: {e}\")\n",
    "        # Provide some default agenda structure rather than failing\n",
    "        return [\n",
    "            {'number': '1', 'title': 'Call to Order'},\n",
    "            {'number': '2', 'title': 'Consent Calendar'},\n",
    "            {'number': '3', 'title': 'Public Hearings'},\n",
    "            {'number': '4', 'title': 'General Business'},\n",
    "            {'number': '5', 'title': 'Non-Agenda Items'},\n",
    "            {'number': '6', 'title': 'Adjournment'}\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_deepseek(example_text, content_text, agenda_items=None):\n",
    "    \"\"\"Use DeepSeek API to summarize text based on example format and agenda structure.\"\"\"\n",
    "    try:\n",
    "        # Truncate texts to fit within token limits\n",
    "        example_text = example_text[:MAX_TOKEN_LENGTH]\n",
    "        content_text = content_text[:MAX_TOKEN_LENGTH]\n",
    "        \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        # Create prompt based on whether we have agenda items\n",
    "        system_prompt = (\n",
    "            \"You are an expert at summarizing meeting transcripts and creating structured notes. \"\n",
    "            \"Your task is to extract key points, decisions, action items, and important discussions \"\n",
    "            \"from meeting transcripts. Format the summary as concise bullet points organized by topic.\"\n",
    "        )\n",
    "        \n",
    "        user_prompt = f\"Here is an example of the summary format I need. Study this format carefully:\\n\\n{example_text}\\n\\n\"\n",
    "        \n",
    "        if agenda_items and len(agenda_items) > 0:\n",
    "            agenda_text = \"\\n\".join([f\"{item['number']}. {item['title']}\" for item in agenda_items])\n",
    "            user_prompt += (\n",
    "                f\"Here is the meeting agenda:\\n\\n{agenda_text}\\n\\n\"\n",
    "                f\"Please summarize the following meeting transcript. Follow the format from the example, \"\n",
    "                f\"but structure your summary according to the agenda items listed above. \"\n",
    "                f\"For each agenda item, extract key points, decisions, action items, and important discussions. \"\n",
    "                f\"Use the agenda item numbers and titles as section headers. \"\n",
    "                f\"To avoid encoding issues, please only use basic ASCII characters (avoid special quotes, dashes, etc.):\\n\\n{content_text}\"\n",
    "            )\n",
    "        else:\n",
    "            user_prompt += (\n",
    "                f\"Please summarize the following meeting transcript. Follow the format from the example, \"\n",
    "                f\"but extract all important information from this specific meeting. \"\n",
    "                f\"Include all key points, decisions, action items, and important discussions as separate bullet points organized by topic. \"\n",
    "                f\"To avoid encoding issues, please only use basic ASCII characters (avoid special quotes, dashes, etc.):\\n\\n{content_text}\"\n",
    "            )\n",
    "        \n",
    "        # Create payload\n",
    "        payload = {\n",
    "            \"model\": \"deepseek-chat\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.3,  # Lower temperature for more focused/factual output\n",
    "            \"max_tokens\": 2000,  # Adjust based on your needs\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        logger.info(\"Sending request to DeepSeek API\")\n",
    "        response = requests.post(DEEPSEEK_API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        summary = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        logger.info(f\"Successfully received summary ({len(summary)} characters)\")\n",
    "        return summary\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"API request error: {e}\")\n",
    "        if hasattr(e.response, 'text'):\n",
    "            logger.error(f\"API response: {e.response.text}\")\n",
    "        raise\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Unexpected API response format: {e}\")\n",
    "        logger.error(f\"Response content: {response.text if 'response' in locals() else 'No response'}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during summarization: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meeting_info(url):\n",
    "    \"\"\"Extract meeting title, date, and other metadata from the URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        meeting_info = {}\n",
    "        \n",
    "        # Try to find meeting title\n",
    "        title_elem = soup.find('span', class_=lambda x: x and 'MeetingTitle' in x)\n",
    "        if title_elem:\n",
    "            meeting_info['title'] = title_elem.get_text(strip=True)\n",
    "        \n",
    "        # Try to find meeting date\n",
    "        date_elem = soup.find('span', class_=lambda x: x and 'MeetingDate' in x)\n",
    "        if date_elem:\n",
    "            meeting_info['date'] = date_elem.get_text(strip=True)\n",
    "        \n",
    "        # Try to find meeting body/committee\n",
    "        body_elem = soup.find('span', class_=lambda x: x and 'BodyName' in x)\n",
    "        if body_elem:\n",
    "            meeting_info['body'] = body_elem.get_text(strip=True)\n",
    "            \n",
    "        return meeting_info\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting meeting info: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was generated with Github Copilot. I'm not sure if temperature etc. values are right.\n",
    "\n",
    "def summarize_with_deepseek(example_text, content_text, agenda_items=None):\n",
    "    \"\"\"Use DeepSeek API to summarize text based on example format and agenda structure.\"\"\"\n",
    "    try:\n",
    "        # Truncate texts to fit within token limits\n",
    "        example_text = example_text[:MAX_TOKEN_LENGTH]\n",
    "        content_text = content_text[:MAX_TOKEN_LENGTH]\n",
    "        \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        # Create prompt based on whether we have agenda items\n",
    "        system_prompt = (\n",
    "            \"You are an expert at summarizing meeting transcripts and creating structured notes. \"\n",
    "            \"Your task is to extract key points, decisions, action items, and important discussions \"\n",
    "            \"from meeting transcripts. Format the summary as concise bullet points organized by topic.\"\n",
    "        )\n",
    "        \n",
    "        user_prompt = f\"Here is an example of the summary format I need. Study this format carefully:\\n\\n{example_text}\\n\\n\"\n",
    "        \n",
    "        if agenda_items and len(agenda_items) > 0:\n",
    "            agenda_text = \"\\n\".join([f\"{item['number']}. {item['title']}\" for item in agenda_items])\n",
    "            user_prompt += (\n",
    "                f\"Here is the meeting agenda:\\n\\n{agenda_text}\\n\\n\"\n",
    "                f\"Please summarize the following meeting transcript. Follow the format from the example, \"\n",
    "                f\"but structure your summary according to the agenda items listed above. \"\n",
    "                f\"For each agenda item, extract key points, decisions, action items, and important discussions. \"\n",
    "                f\"Use the agenda item numbers and titles as section headers. \"\n",
    "                f\"To avoid encoding issues, please only use basic ASCII characters (avoid special quotes, dashes, etc.):\\n\\n{content_text}\"\n",
    "            )\n",
    "        else:\n",
    "            user_prompt += (\n",
    "                f\"Please summarize the following meeting transcript. Follow the format from the example, \"\n",
    "                f\"but extract all important information from this specific meeting. \"\n",
    "                f\"Include all key points, decisions, action items, and important discussions as separate bullet points organized by topic. \"\n",
    "                f\"To avoid encoding issues, please only use basic ASCII characters (avoid special quotes, dashes, etc.):\\n\\n{content_text}\"\n",
    "            )\n",
    "        \n",
    "        # Create payload\n",
    "        payload = {\n",
    "            \"model\": \"deepseek-chat\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.3,  # Lower temperature for more focused/factual output\n",
    "            \"max_tokens\": 2000,  # Adjust based on your needs\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        logger.info(\"Sending request to DeepSeek API\")\n",
    "        response = requests.post(DEEPSEEK_API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        summary = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        logger.info(f\"Successfully received summary ({len(summary)} characters)\")\n",
    "        return summary\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"API request error: {e}\")\n",
    "        if hasattr(e.response, 'text'):\n",
    "            logger.error(f\"API response: {e.response.text}\")\n",
    "        raise\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Unexpected API response format: {e}\")\n",
    "        logger.error(f\"Response content: {response.text if 'response' in locals() else 'No response'}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during summarization: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated with Github Copilot due to an error I got\n",
    "def normalize_text_for_pdf(text):\n",
    "    \"\"\"Normalize text to make it compatible with FPDF\"\"\"\n",
    "    # Replace problematic Unicode characters with ASCII alternatives\n",
    "    text = text.replace('\\u2019', \"'\")  # Replace right single quotation with ASCII single quote\n",
    "    text = text.replace('\\u2018', \"'\")  # Replace left single quotation with ASCII single quote\n",
    "    text = text.replace('\\u201c', '\"')  # Replace left double quotation with ASCII double quote\n",
    "    text = text.replace('\\u201d', '\"')  # Replace right double quotation with ASCII double quote\n",
    "    text = text.replace('\\u2013', '-')  # Replace en dash with hyphen\n",
    "    text = text.replace('\\u2014', '--')  # Replace em dash with double hyphen\n",
    "    text = text.replace('\\u2026', '...')  # Replace ellipsis with three dots\n",
    "    \n",
    "    # For remaining problematic characters, use a more aggressive approach\n",
    "    normalized_text = ''\n",
    "    for char in text:\n",
    "        if ord(char) < 128:\n",
    "            normalized_text += char\n",
    "        else:\n",
    "            # Try to find an ASCII equivalent or use a fallback character\n",
    "            try:\n",
    "                normalized = unicodedata.normalize('NFKD', char).encode('ASCII', 'ignore').decode('ASCII')\n",
    "                normalized_text += normalized if normalized else '_'\n",
    "            except:\n",
    "                normalized_text += '_'\n",
    "    \n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf(content, output_path, meeting_info=None):\n",
    "    \"\"\"Create a PDF with the provided content.\"\"\"\n",
    "    try:\n",
    "        # Handle Unicode characters properly for FPDF\n",
    "        cleaned_content = normalize_text_for_pdf(content)\n",
    "        \n",
    "        pdf = FPDF()\n",
    "        pdf.set_auto_page_break(auto=True, margin=15)\n",
    "        pdf.add_page()\n",
    "        \n",
    "        # Add a title\n",
    "        pdf.set_font(\"Arial\", 'B', size=16)\n",
    "        title = \"Meeting Summary\"\n",
    "        if meeting_info and 'title' in meeting_info:\n",
    "            title = normalize_text_for_pdf(meeting_info['title'])\n",
    "        pdf.cell(0, 10, title, ln=True, align='C')\n",
    "        \n",
    "        # Add meeting metadata if available\n",
    "        if meeting_info:\n",
    "            pdf.set_font(\"Arial\", 'I', size=10)\n",
    "            if 'date' in meeting_info:\n",
    "                pdf.cell(0, 6, f\"Date: {meeting_info['date']}\", ln=True)\n",
    "            if 'body' in meeting_info:\n",
    "                pdf.cell(0, 6, f\"Body: {meeting_info['body']}\", ln=True)\n",
    "        \n",
    "        pdf.ln(5)\n",
    "        \n",
    "        # Add content\n",
    "        pdf.set_font(\"Arial\", size=11)\n",
    "        \n",
    "        # Check for markdown-style headers or agenda item headers\n",
    "        in_list = False\n",
    "        \n",
    "        for line in cleaned_content.split('\\n'):\n",
    "            # Reset font to normal for each line\n",
    "            pdf.set_font(\"Arial\", size=11)\n",
    "            \n",
    "            # Check for headings (various formats)\n",
    "            if re.match(r'^#+\\s+', line) or re.match(r'^[0-9]+\\.\\s+', line):\n",
    "                # This is a heading line (markdown or numbered)\n",
    "                pdf.set_font(\"Arial\", 'B', size=13)\n",
    "                clean_heading = re.sub(r'^#+\\s+', '', line)  # Remove markdown heading markers\n",
    "                pdf.ln(5)\n",
    "                pdf.multi_cell(0, 10, clean_heading)\n",
    "                pdf.ln(2)\n",
    "                in_list = False\n",
    "            elif line.strip().startswith('- ') or line.strip().startswith('* '):\n",
    "                # This is a bullet point\n",
    "                if not in_list:\n",
    "                    pdf.ln(2)  # Add space before first bullet point in a list\n",
    "                    in_list = True\n",
    "                \n",
    "                # Extract the bullet content and format it\n",
    "                bullet_content = line.strip()[2:].strip()\n",
    "                \n",
    "                # Check if this bullet has sub-bullets (indentation)\n",
    "                indent = 10\n",
    "                if bullet_content.startswith('  '):\n",
    "                    indent = 15\n",
    "                \n",
    "                # Position for bullet\n",
    "                pdf.set_x(pdf.l_margin + indent)\n",
    "                \n",
    "                # Add bullet character\n",
    "                current_x = pdf.get_x()\n",
    "                current_y = pdf.get_y()\n",
    "                pdf.cell(5, 5, chr(149), ln=0)  # Unicode for bullet point\n",
    "                \n",
    "                # Add content after bullet\n",
    "                pdf.set_xy(current_x + 5, current_y)\n",
    "                pdf.multi_cell(0, 6, bullet_content)\n",
    "            else:\n",
    "                # Regular paragraph text\n",
    "                if line.strip():  # Only if line is not empty\n",
    "                    if in_list:\n",
    "                        pdf.ln(2)  # Add space after a list\n",
    "                        in_list = False\n",
    "                    pdf.multi_cell(0, 6, line)\n",
    "        \n",
    "        # Save PDF\n",
    "        pdf.output(output_path)\n",
    "        logger.info(f\"PDF saved successfully at {output_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating PDF: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main (calling everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 23:57:37,939 - INFO - Starting caption note summarization process\n",
      "2025-03-14 23:57:38,432 - INFO - Successfully extracted 12153 characters from PDF\n",
      "2025-03-14 23:57:38,433 - INFO - Fetching content from URL: https://sunnyvaleca.legistar.com/Transcript.aspx?ID1=4623&G=FA76FAAA-7A74-41EA-9143-F2DB1947F9A5\n",
      "2025-03-14 23:57:40,098 - INFO - Successfully extracted 214004 characters from URL\n",
      "2025-03-14 23:57:43,994 - INFO - Fetching agenda from URL: https://sunnyvaleca.legistar.com/View.ashx?M=AADA&ID=1143202&GUID=2293974F-52E3-4282-80E0-3AA32AC2C482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching agenda from URL: https://sunnyvaleca.legistar.com/View.ashx?M=AADA&ID=1143202&GUID=2293974F-52E3-4282-80E0-3AA32AC2C482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 23:57:45,225 - INFO - Found 9 agenda items\n",
      "2025-03-14 23:57:45,226 - INFO - Sending request to DeepSeek API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HTML content to agenda_debug.html for inspection\n",
      "Found 0 agenda items with class 'MeetingItem'\n",
      "Trying to find agenda items by looking for bold text within relevant containers\n",
      "Trying to find agenda items by looking for elements with font-weight in style\n",
      "Trying to find agenda items by looking for styled DIVs\n",
      "Trying to find agenda items by looking for common agenda patterns\n",
      "Found 0 agenda items:\n",
      "Using hard-coded agenda items for this specific document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 23:58:27,127 - INFO - Successfully received summary (3306 characters)\n",
      "2025-03-14 23:58:27,133 - INFO - PDF saved successfully at summarized_output.pdf\n",
      "2025-03-14 23:58:27,134 - INFO - Process completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized document saved successfully as summarized_output.pdf\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to coordinate the workflow.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Starting caption note summarization process\")\n",
    "        \n",
    "        # Extract text from example PDF\n",
    "        example_text = extract_text_from_pdf(PDF_EXAMPLE_PATH)\n",
    "        \n",
    "        # Extract text from target webpage (transcript)\n",
    "        content_text = extract_text_from_url(TARGET_URL)\n",
    "        \n",
    "        # Try to get meeting info from transcript URL\n",
    "        meeting_info = extract_meeting_info(TARGET_URL)\n",
    "        \n",
    "        # Extract agenda items (required)\n",
    "        agenda_items = extract_agenda_items(AGENDA_URL)\n",
    "        if not agenda_items:\n",
    "            logger.error(\"No agenda items found in the provided agenda URL. Cannot proceed.\")\n",
    "            raise ValueError(\"No agenda items found in the provided agenda URL\")\n",
    "        \n",
    "        # Generate summary using DeepSeek API\n",
    "        summary = summarize_with_deepseek(example_text, content_text, agenda_items)\n",
    "        \n",
    "        # Create and save PDF\n",
    "        create_pdf(summary, OUTPUT_PDF_PATH, meeting_info)\n",
    "        \n",
    "        logger.info(\"Process completed successfully\")\n",
    "        print(f\"Summarized document saved successfully as {OUTPUT_PDF_PATH}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Process failed: {e}\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
